https://zhuanlan.zhihu.com/p/82571138

## 一、 概念理解

在机器学习初期，我们经常会接触一些概念，比如模式识别，统计学习，数据挖掘，机器学习，深度学习...。在我们看来这些概念好像都在讲同样的算法，那它们之间有什么区别呢？

首先我们可以先给这些概念下一个简单的定义：

- 模式识别：根据给定的特征对对象的模式进行分类，是用于决策系统的重要部分。
- 机器学习：机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。
- 统计学习：根据经验数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。
- 深度学习：是一种以人工神经网络为架构，对数据进行表征学习的算法。深度学习能够自主提取对象的特征。
- 数据挖掘：识别出海量数据中有效的、新颖的、潜在有用的、最终可理解的模式的非平凡过程（有价值/规律的信息）。

单从定义上来说，我们还是不能够直观的区分这些概念。下面我们用西瓜的例子来对这几个概念进行区分。假设我们刚刚从计算机专业毕业，但是由于就业形势不佳，我们被迫回老家做了瓜农。我们发现做瓜农需要有丰富的经验才能在不破坏瓜的情况下挑出那些好瓜，虽然我们并没有丰富的挑瓜经验，但是我们希望能够利用学到的计算机知识制作一个机器来帮助我们挑瓜，这样就能大大加快效率。于是，我们想到去向有经验的瓜农请教，得知：声音脆的，颜色淡的，纹理稀疏的瓜是好瓜的概率大，于是我们就可以设计一个机器，当我输入这几个参数时，机器会告诉我们这个瓜是不是好瓜。这个时候机器单纯给了我们一个识别的结果，但是后续的事情（比如如何给这个瓜定一个合适的售价）需要我们自己完成。【以上的过程可以认为是模式识别的过程】。一阵高兴之后，我们发现，我们对瓜的定价也是一无所知，于是我们又想让机器帮我们完成这个任务，那么现在，我们需要采集历史价格信息，比如瓜的质量，出售时间，以及地域等都会影响瓜的价格，我们希望机器能够从这些数据中学习出一个模型，然后用这个模型可以直接判别瓜的好坏，并给瓜定价，这样机器本身就可以胜任瓜农的角色了。【以上的过程可以认为是机器学习的过程】。那么这个机器应该怎么建立预测模型呢？我们很容易会想到使用统计学的方法，比如根据历史经验，我们认为出现次数多的情况更加接近真实情况（比如声音脆的瓜往往是好瓜，价格要高一点儿，于是我们可以给这个特征一个大的权重），那些出现少的情况自然会被分一个小权重。我们用加权结果来预测结果。【以上过程使用了统计学方法，仍然需要人为提供特征，我们可以认为这是统计学习方法】。但是很快我们发现了一个问题，我们的机器并没有老瓜农的判断精确，于是我们又去请教了老瓜农。这次我们发现其实除了这些主要特征之外，还会有许多细节或者是组合出现的特征都会影响瓜的判断，就拿最简单的颜色深浅来说，色度可以划分到很细（不单单是深浅两种可能），而且当有其他特征和颜色同时出现时，同一种颜色可能也会有不同的结果。甚至老瓜农还说，有时候他们会靠直觉来判断瓜的好坏。这样一来，我们很难人工建立一个这么健全的模型，还好我们学过神经网络模型可以自己提取到数据的特征，于是我们使用了神经网络模型，只需要将瓜的照片数据，声音数据，价格数据喂给模型，模型会自动从当中抽取出特征，然后再做出判断。【这个过程可以认为是深度学习模型】。

总结来说，模式识别是机器学习的前身，它只能完成模式分类的任务，重心放在能够正确识别模式上。机器学习则侧重于能够利用已有的经验知识预测未知的结果，重心放在预测结果精准度上，可以是分类问题也可以是回归问题。统计学习和深度学习是两种基于不同方法的机器学习。数据挖掘则是在海量的数据中找出有价值的信息，它的输出形式和机器学习略有区别（对于有模式的数据，可以学习出数据的模式分类；对于有一定发展规律的数据，可以学习出数据发展的回归函数；对于相关的数据，可以学习出数据之间的关联关系...），侧重点是在已有的海量数据中发现有价值的信息，不在预测未来数据上。用一个关系图来表示它们的关系如下：

<img src=".asserts/image-20240702163305185.png" alt="image-20240702163305185" style="zoom:50%;" />



## 二、机器学习方法的分类

机器学习方法按照不同的属性可以划分为不同的类别。比如：

- 按照是否需要标签样本分类，可以将模型分为以下几类：有监督模型，无监督模型和半监督模型。

<img src=".asserts/image-20240702163334740.png" alt="image-20240702163334740" style="zoom:50%;" />

* 按照模型预测结果类型划分，可以将模型分为以下几类：分类模型，回归模型，序列标注模型。

<img src=".asserts/image-20240704150441621.png" alt="image-20240704150441621" style="zoom:50%;" />

* 按照最终学到的模型类型划分，有监督模型又可以分为：判别式模型和生成式模型。判别式模型本身学到的就是一个条件概率函数P(Y|X)或者判别函数Y=f(X)，根据输入X可以直接输出分类或分类的概率（如 决策树，支持向量机，逻辑回归等）；生成式模型学到的内容是一个联合概率密度函数P(X,Y), 需要通过P(X,Y)/P(X)计算得到条件概率函数P(Y|X)（如 朴素贝叶斯和隐马尔可夫模型等）。

本系列中我将会把这些模型按照模型本身的原理进行分类和学习，主要目的是为了便于对比理解，结构看起来清晰一点儿，可能分类会有一定的不当之处。

- 按照模型原理，可以划分为：基于距离的回归分类模型，基于树结构的回归分类模型，基于划分超平面的回归分类模型，基于概率图的分类回归模型，和基于神经网络的回归分类模型。

1. 基于距离的模型：往往利用样本之间的度量距离来描述样本间的相似性，进而完成下游分类回归任务。如，KNN以及部分聚类算法。
2. 基于树结构的模型：以决策树为基本单元构建的模型。如，决策树以及以树模型构成的集成学习方法和提升学习方法。
3. 基于划分超平面的模型：模型的核心是寻找一个划分超平面，在此基础上完成分类任务。如SVM和逻辑回归。
4. 基于概率图的模型：以概率图为基础构建的模型。如，贝叶斯网络，HMM和CRF。
5. 基于神经网络的模型：以神经元为基本单元构建的模型。如，感知机，MLP，卷积神经网络和循环神经网络。



## 三、机器学习方法的三要素

这一节的内容主要来自于《统计学习方法》，机器学习方法的三要素是模型，策略和优化算法。

3.1 模型

模型就是所要学习的条件概率分布或者决策函数，由模型的结构和参数共同构成。模型结构可以理解为函数形式或者是概率图（比如选择n次线性方程作为模型结构或者n层神经网络作为模型机构），当结构确定下来之后，参数的个数也会随之确定下来。因为每一组参数都构成一个模型，所以无数的参数可能取值就构成了无数个备选的模型。所有的模型构成了假设空间。参数的变化空间也叫参数空间。

模型的假设空间包含所有可能的模型，一般为无穷多个。模型的训练过程就是在假设空间中找到一个最优解。

3.2 策略

策略可以理解为评价模型优劣的方法，具体来说是通过评价模型预测结果优劣来判定模型优劣的方法。这里引入两个函数，一个是损失函数，一个是风险函数。

- 损失函数：描述预测结果和真实的结果之间的误差，损失函数越小，模型越好。常见的几种损失函数如下：

<img src=".asserts/image-20240717163923991.png" alt="image-20240717163923991" style="zoom:50%;" />

- 风险函数：对损失函数求平均。如果我们按照样本分布的概率密度对损失函数做加权的平均，那么得到的结果是期望风险。如果我们将样本平等看待，直接对损失函数求平均，那么得到的结果是经验风险。实际应用当中样本分布往往未知，所以一般会使用经验风险函数。

最优模型应该做到以下两点，经验风险最小和结构风险最小。

- 经验风险最小：经验风险函数在上面已经提到过，最优模型需要使得经验风险最小。可以理解为在确定的模型结构下选择最有的参数组合使模型达到最优。
- 结构风险最小：结构风险可以理解为通过调整模型结构使得模型达到最优。（通过上面的描述，我们可以发现模型结构往往是在训练前就被人为指定好了，但是我们并不能保证指定的结构就比其他的结构要好，为了防止选择太离谱的结构，引入了结构风险。）结构在这里可以理解为参数的规模，参数越多结构越复杂，所以我们需要通过一种方法来控制结构的复杂性，选择出最合适的结构规模。这种办法就是正则化方法。后面会具体讲到。

3.3 优化算法

优化算法是指如何找到最优解的方法，不仅仅局限于我们都听过的梯度下降算法。比如，对于连续可导函数，可以直接通过求导求最优解。当函数过于复杂，参数过多时，求导方法往往不太实用，我们通常采用梯度下降的方法来逼近最优解（可能永远得不到最优解）。另外在概率图模型当中，也可以用极大似然估计的方法来获得最优解，也可是实用EM算法来求解带有隐藏变量的最优化问题。此外，还有一些带约束的最优化问题（如SVM求解），拉格朗日乘子法方法求解等等。具体的算法细节在后续章节中会一一讲到。

总结来看，模型是定义了解空间，策略定义了什么是最优解，优化算法是在解空间中寻找最优解的方法。三者结合就能够完整的求解出一个问题的最优解。



## 四、模型评估&选择

在第三节中，我们提到经验风险函数（或叫经验误差）可以来评估一个模型的优劣。实际上，在给定训练数据集的情况下，只要模型的复杂度足够高，我们总能把经验误差降低到0（比如我们建一个足够复杂的决策树，每个叶节点只有一个样本，对应输出是正确结果），那么这个模型是最优解吗？显然并不是。这种模型不具备预测新数据的能力，我们称这种模型“过拟合”了。与过拟合对应的是“欠拟合”，指模型学习能力低，不能够胜任任务，不能达到一个理想的精度（精度=1-错误率）。

![image-20240717165329586](.asserts/image-20240717165329586.png)

那么，评估过程应该怎么实际操作呢？一个直观的想法就是我们从训练集中抽出一部分作为测试集（测试集应该尽量不在训练过程中使用），在模型训练完成后，用测试集来进行验证，测试模型在未知数据上的表现。下面介绍三种抽取测试集的方法。

- 留出法：直接将标注数据集划分成训练集合测试集两个互斥的部分，一般训练集占2/3~4/5，剩余的作为测试集。这种方法比较简单，但是有一部分标记数据没有参与训练，会造成一定的浪费。
- 交叉验证法：对标记数据多次使用留出法（每次都选择不同的划分），最后用多次划分结果中测试集表现的平均值作为测试结果。这样保证了全部数据都参与了运算，而且每次的测试集合训练集是互斥的。
- 自助法：采用有放回的抽样方法，在m个样本中抽出m个样本作为训练集，将始终没有抽到的样本作为测试集。每次不被抽到的概率是1-1/m，m次都没有被抽到的概率是0.368.这个比例也刚好合适做测试集。

<img src=".asserts/image-20240717185733915.png" alt="image-20240717185733915" style="zoom:50%;" />

有了评估方法之后，我们应该制定一个标准来筛选优秀的模型。那么应该怎么度量一个模型的性能呢？对于回归任务来说主要使用的是均方误差：

<img src=".asserts/image-20240717185746231.png" alt="image-20240717185746231" style="zoom:50%;" />

分类问题的度量相对比较复杂，下面介绍几种常见的方法：

- ***错误率与精度***：错误率为预测错误的数量占总样本的比重，用E(f;D)表示；精度为预测正确的数量占总样本的比重，用Acc(f;D)表示。当样本分布不对称时，这种平均方法往往没有实际价值。（比如一百个样例中有98个正例，2个反例，那么模型不需要任何训练，直接输出正，精度就能达到98%，这显然是不合理的）

<img src=".asserts/image-20240717185800939.png" alt="image-20240717185800939" style="zoom:50%;" />

* 查准率、查全率与F1：为了避免上面描述的缺陷，引入F1评分。首先所有的预测样本一定属于真正例（预测和实际都为正例）、假正例（预测为正例，实际为反例）、真反例（预测和实际都为反例）、假反例（预测为反例，实际为正例）四种情况中的一种。且TP+FP+TN+FN=样本总数。定义查准率P=TP/(TP+FP)和查全率R=TP/(TP+FN)。

<img src=".asserts/image-20240717185833184.png" alt="image-20240717185833184" style="zoom:50%;" />

当模型固定后，我们可以通过调节分类阈值来改变查准率和查全率，我们会发现这两个值是一组矛盾的度量，当一个值变大时，另一个值会相应的减小。通过不断改变阈值，我们会得到这个模型的一条P-R曲线。不同的模型会有不同的P-R曲线。曲线与坐标轴包围的面积越大，说明模型越好。

<img src=".asserts/image-20240717185846756.png" alt="image-20240717185846756" style="zoom:50%;" />

通过计算面积来比较模型优劣还是有点麻烦，我们可以用一个公式来等价描述这个性能度量，这就是F1度量。

<img src=".asserts/image-20240717185857616.png" alt="image-20240717185857616" style="zoom:50%;" />

* ***ROC与AUC***：ROC是一条曲线（图中的绿色曲线），AUC是曲线与轴边界围成的面积（图中阴影面积）。ROC与上面的P-R曲线的获得方法完全一样，只不过是横纵坐标轴不同，P-R曲线的横纵坐标轴分别是查全率和查准率。ROC曲线的横坐标轴是假正例率（用FPR表示），纵坐标轴是真正例率（用TPR表示）。AUC可以通过积分来求解，值越大，模型越好。

<img src=".asserts/image-20240717185926778.png" alt="image-20240717185926778" style="zoom:50%;" />

* ***代价敏感错误率与代价曲线***：在实际生活中，把正例识别成反例，和把反例识别成正例往往造成的损失是不同的，不如把良性肿瘤误判成恶性肿瘤不会造成患者丧失生命，然而如果我们把恶性肿瘤误诊成良性，往往会错过最佳的治疗时间，造成不可挽回的损失。所以这两种错误往往代价不同。那么我们在计算误差时，需要对不同的情况分配一个权重，此时计算的错误率称作代价敏感错误率。

<img src=".asserts/image-20240717185944215.png" alt="image-20240717185944215" style="zoom:50%;" />

代价曲线将代价因素考虑曲线生成的过程当中，可以直接在图中反应出模型的期望总代价。

到现在，看起来我们只需要比较性能度量的大小就能选择最优模型了，但是实际中仍然需要考虑一个问题：我们计算的误差都是在测试集上计算的，测试集上的误差能代表真实数据的误差（或叫泛化误差）吗？虽然两个误差相关性很大，但是并不能够完全相互取代。我们只能先假设测试误差=泛化误差，然后用“假设检验”的方法来验证这个假设的可信度，当可信度超过一定的阈值（或在接受域内）时，我们就可以认为测试误差近似等于泛化误差。那怎么验证这个假设呢？下面会介绍几种方法。

- 二项检验：计算泛化误差被估计成测试误差的概率分布P：

<img src=".asserts/image-20240717190002724.png" alt="image-20240717190002724" style="zoom:50%;" />

该分布服从二项分布，取显著度a(一般为0.05-0.1)，当P(泛化误差<=测试误差)>=1-a时，我们就认为假设是可以接受的。

- t检验：重复多次留出法后，我们会得到多个测试误差，然后套用t检验的公式，用采样的方差来近似实际方差，然后再检验均值假设。
