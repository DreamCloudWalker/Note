https://zhuanlan.zhihu.com/p/349179328

通过视频进行动作捕捉，因为其设备成本低，演员负担小，算得上是动捕领域的圣杯，今年颇有些值得称道的进展，在此为大家做一总结。

首先是三个容易使用的，分别是，

**DeepMotion**

[https://deepmotion.com/](https://link.zhihu.com/?target=https%3A//deepmotion.com/)

**RADiCAL**

[https://getrad.co/](https://link.zhihu.com/?target=https%3A//getrad.co/)

**ThreeDPoseUnityBarracuda**

[https://github.com/digital-standard/ThreeDPoseUnityBarracuda](https://link.zhihu.com/?target=https%3A//github.com/digital-standard/ThreeDPoseUnityBarracuda)

前两者是云端服务，你把视频传上去之后，过段时间可以下载解析好的动作文件，两者都提供了试用期，方便大家测试。

ThreeDPoseUnityBarracuda 则是独立的 Unity 程序，可以直接从摄像头读取视频流，也可以添加视频文件，推荐 2060 以上显卡使用。

先上一段三者的解析比较，

https://www.zhihu.com/zvideo/1340615641989070849



可以看出，

\1. RADiCAL 虽然出错的动作最少，但是形体佝偻，动作拘谨，少女成了老太，

\2. ThreeDPoseUnityBarracuda 启动之后需要一段热身时间，但由于另外两者是离线解析，是否同样需要热身时间并未可知，

\3. DeepMotion 与 ThreeDPoseUnityBarracuda 相比，感觉 ThreeDPoseUnityBarracuda 动作更到位，出错更少，比如 00:09-00:14 那段叉腰扭胯，

\4. 当然，这段视频本身是 ThreeDPoseUnityBarracuda 项目中的演示视频，可能 ThreeDPoseUnityBarracuda 有主场优势。

所以结论是，如果你有台尚且体面的电脑，ThreeDPoseUnityBarracuda 无疑是你的首选，如果电脑配置不够，那笔者的推荐是 DeepMotion。至于 DeepMotion 和 RADiCAL 的收费，最低月费分别是，DeepMotion 20美刀，含 8 分钟动画解析，RADiCAL 8 美刀，含 3 分钟，区别不大。

----------编辑

评论中有人提到小K动捕，一并列出。

[小K网-小K动画制作平台](https://link.zhihu.com/?target=https%3A//xk.yunboai.com/)



从结果来看质量介于 DeepMotion 和 RADiCAL 间，优点是免费且导出格式更为丰富。

----------编辑完

除了上面三个，还有些方案环境配置比较折腾，不过我们可以借 Google Colab 略窥一斑。以下列出诸方案的 Google Colab 连接，以及运行 Colab 可以得到的示例结果。

**Google Mediapipe**

[google/mediapipe](https://link.zhihu.com/?target=https%3A//github.com/google/mediapipe)

Colab：

[https://colab.research.google.com](https://link.zhihu.com/?target=https%3A//colab.research.google.com/github/cedro3/mediapipe/blob/main/mediapipe_for_movie.ipynb)

演示效果：

https://vdn.vzuu.com/SD/c2d4b52e-6695-11eb-b096-3a26988c8260.mp4?disable_local_cache=1&bu=078babd7&c=avc.0.0&f=mp4&expiration=1719836866&auth_key=1719836866-0-0-c3b0f8454d36bdc0ea984a21da80f228&v=ali&pu=078babd7



**Facebook FrankMocap**

[https://github.com/facebookresearch/frankmocap](https://link.zhihu.com/?target=https%3A//github.com/facebookresearch/frankmocap)

可惜网上没有找到比较好用的 FrankMocap 的 Colab。

**CMU OpenPose**

[https://github.com/CMU-Perceptual-Computing-Lab/openpose](https://link.zhihu.com/?target=https%3A//github.com/CMU-Perceptual-Computing-Lab/openpose)

Colab：

[https://colab.research.google.com](https://link.zhihu.com/?target=https%3A//colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb)